{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "190d40db-f1a5-45a3-812a-22a145db7c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason Ng\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.7789667788358388\n",
      "Test  R^2:  0.5933736676584871\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OMP_NUM_THREADS=1\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "root = \"tensile_fatigue_data_v14.xlsx\"\n",
    "main_df = pd.read_excel(root)\n",
    "\n",
    "X = pd.read_excel(root,usecols=[0,1,2,3,4])\n",
    "y = pd.read_excel(root,usecols=[6])\n",
    "\n",
    "# Normalize inputs\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size= 0.2, random_state = 10)\n",
    "\n",
    "# Stack inputs and output for joint modeling\n",
    "XY = np.hstack([X_train, y_train.reshape(-1, 1)])  # shape (n_samples, 6)\n",
    "\n",
    "# Fit a Gaussian Mixture Model to the joint distribution\n",
    "n_components = 6\n",
    "gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=42)\n",
    "gmm.fit(XY)\n",
    "\n",
    "def gmr_multivariate(gmm, X_query):\n",
    "    \"\"\"\n",
    "    Perform Gaussian Mixture Regression with multivariate X and scalar Y.\n",
    "    :param gmm: Trained GaussianMixture model (on joint [X, Y])\n",
    "    :param X_query: Input queries of shape (n_queries, n_features)\n",
    "    :return: Predicted Y values (mean), shape (n_queries,)\n",
    "    \"\"\"\n",
    "    n_queries = X_query.shape[0]\n",
    "    n_features = X_query.shape[1]\n",
    "    y_preds = np.zeros(n_queries)\n",
    "\n",
    "    for i in range(n_queries):\n",
    "        x = X_query[i].reshape(-1, 1)  # shape (n_features, 1)\n",
    "\n",
    "        weights = []\n",
    "        means = []\n",
    "\n",
    "        for k in range(gmm.n_components):\n",
    "            mu = gmm.means_[k].reshape(-1, 1)          # shape (6, 1)\n",
    "            Sigma = gmm.covariances_[k]                # shape (6, 6)\n",
    "\n",
    "            mu_x = mu[:n_features]\n",
    "            mu_y = mu[n_features:]\n",
    "            Sigma_xx = Sigma[:n_features, :n_features]\n",
    "            Sigma_xy = Sigma[:n_features, n_features:]\n",
    "            Sigma_yx = Sigma[n_features:, :n_features]\n",
    "            Sigma_yy = Sigma[n_features:, n_features:]\n",
    "\n",
    "            # Compute conditional mean E[Y | X=x]\n",
    "            inv_Sigma_xx = np.linalg.inv(Sigma_xx)\n",
    "            cond_mean = mu_y + Sigma_yx @ inv_Sigma_xx @ (x - mu_x)  # shape (1, 1)\n",
    "            means.append(cond_mean.flatten())\n",
    "\n",
    "            # Compute responsibility (weight) for component k\n",
    "            diff = x.flatten() - mu_x.flatten()\n",
    "            exponent = -0.5 * diff @ inv_Sigma_xx @ diff\n",
    "            norm_const = np.sqrt((2 * np.pi) ** n_features * np.linalg.det(Sigma_xx))\n",
    "            prob = np.exp(exponent) / norm_const\n",
    "            weights.append(gmm.weights_[k] * prob)\n",
    "\n",
    "        weights = np.array(weights)\n",
    "        weights /= np.sum(weights)\n",
    "        means = np.array(means).flatten()\n",
    "        y_preds[i] = np.sum(weights * means)\n",
    "\n",
    "    return y_preds\n",
    "\n",
    "# Query on test inputs\n",
    "y_train_pred = gmr_multivariate(gmm, X_train)\n",
    "y_test_pred = gmr_multivariate(gmm, X_test)\n",
    "\n",
    "var_train = r2_score(y_train, y_train_pred)\n",
    "var_test  = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train R^2: \", var_train)\n",
    "print(\"Test  R^2: \", var_test)\n",
    "\n",
    "# Plot prediction vs true (if available)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"True Y\")\n",
    "plt.ylabel(\"Predicted Y (GMR)\")\n",
    "plt.title(\"Gaussian Mixture Regression (5D → 1D)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a49237-3121-4fce-889f-671594467093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmr_multivariate(gmm, X_query):\n",
    "    \"\"\"\n",
    "    Perform Gaussian Mixture Regression with multivariate X and scalar Y.\n",
    "    :param gmm: Trained GaussianMixture model (on joint [X, Y])\n",
    "    :param X_query: Input queries of shape (n_queries, n_features)\n",
    "    :return: Predicted Y values (mean), shape (n_queries,)\n",
    "    \"\"\"\n",
    "    n_queries = X_query.shape[0]\n",
    "    n_features = X_query.shape[1]\n",
    "    y_preds = np.zeros(n_queries)\n",
    "\n",
    "    for i in range(n_queries):\n",
    "        x = X_query[i].reshape(-1, 1)  # shape (n_features, 1)\n",
    "\n",
    "        weights = []\n",
    "        means = []\n",
    "\n",
    "        for k in range(gmm.n_components):\n",
    "            mu = gmm.means_[k].reshape(-1, 1)          # shape (6, 1)\n",
    "            Sigma = gmm.covariances_[k]                # shape (6, 6)\n",
    "\n",
    "            mu_x = mu[:n_features]\n",
    "            mu_y = mu[n_features:]\n",
    "            Sigma_xx = Sigma[:n_features, :n_features]\n",
    "            Sigma_xy = Sigma[:n_features, n_features:]\n",
    "            Sigma_yx = Sigma[n_features:, :n_features]\n",
    "            Sigma_yy = Sigma[n_features:, n_features:]\n",
    "\n",
    "            # Compute conditional mean E[Y | X=x]\n",
    "            inv_Sigma_xx = np.linalg.inv(Sigma_xx)\n",
    "            cond_mean = mu_y + Sigma_yx @ inv_Sigma_xx @ (x - mu_x)  # shape (1, 1)\n",
    "            means.append(cond_mean.flatten())\n",
    "\n",
    "            # Compute responsibility (weight) for component k\n",
    "            diff = x.flatten() - mu_x.flatten()\n",
    "            exponent = -0.5 * diff @ inv_Sigma_xx @ diff\n",
    "            norm_const = np.sqrt((2 * np.pi) ** n_features * np.linalg.det(Sigma_xx))\n",
    "            prob = np.exp(exponent) / norm_const\n",
    "            weights.append(gmm.weights_[k] * prob)\n",
    "\n",
    "        weights = np.array(weights)\n",
    "        weights /= np.sum(weights)\n",
    "        means = np.array(means).flatten()\n",
    "        y_preds[i] = np.sum(weights * means)\n",
    "\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e063baa-20a4-4703-a740-48b739634ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmr_multivariate(gmm, X_query):\n",
    "    \"\"\"\n",
    "    Perform Gaussian Mixture Regression with multivariate X and scalar Y.\n",
    "    :param gmm: Trained GaussianMixture model (on joint [X, Y])\n",
    "    :param X_query: Input queries of shape (n_queries, n_features)\n",
    "    :return: Predicted Y values (mean), shape (n_queries,)\n",
    "    \"\"\"\n",
    "    n_queries = X_query.shape[0]\n",
    "    n_features = X_query.shape[1]\n",
    "    y_preds = np.zeros(n_queries)\n",
    "\n",
    "    for i in range(n_queries):\n",
    "        x = X_query[i].reshape(-1, 1)  # shape (n_features, 1)\n",
    "\n",
    "        weights = []\n",
    "        means = []\n",
    "\n",
    "        for k in range(gmm.n_components):\n",
    "            mu = gmm.means_[k].reshape(-1, 1)          # shape (6, 1)\n",
    "            Sigma = gmm.covariances_[k]                # shape (6, 6)\n",
    "\n",
    "            mu_x = mu[:n_features]\n",
    "            mu_y = mu[n_features:]\n",
    "            Sigma_xx = Sigma[:n_features, :n_features]\n",
    "            Sigma_xy = Sigma[:n_features, n_features:]\n",
    "            Sigma_yx = Sigma[n_features:, :n_features]\n",
    "            Sigma_yy = Sigma[n_features:, n_features:]\n",
    "\n",
    "            # Compute conditional mean E[Y | X=x]\n",
    "            inv_Sigma_xx = np.linalg.inv(Sigma_xx)\n",
    "            cond_mean = mu_y + Sigma_yx @ inv_Sigma_xx @ (x - mu_x)  # shape (1, 1)\n",
    "            means.append(cond_mean.flatten())\n",
    "\n",
    "            # Compute responsibility (weight) for component k\n",
    "            diff = x.flatten() - mu_x.flatten()\n",
    "            exponent = -0.5 * diff @ inv_Sigma_xx @ diff\n",
    "            norm_const = np.sqrt((2 * np.pi) ** n_features * np.linalg.det(Sigma_xx))\n",
    "            prob = np.exp(exponent) / norm_const\n",
    "            weights.append(gmm.weights_[k] * prob)\n",
    "\n",
    "        weights = np.array(weights)\n",
    "        weights /= np.sum(weights)\n",
    "        means = np.array(means).flatten()\n",
    "        y_preds[i] = np.sum(weights * means)\n",
    "\n",
    "    return y_preds\n",
    "\n",
    "def GMM_NN(variable):\n",
    "\n",
    "    # 1. Prepare the data\n",
    "    df_x = pd.read_excel(root,usecols=[0,1,2,3,4])\n",
    "    df_y = pd.read_excel(root,usecols=[variable])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    # Stack inputs and output for joint modeling\n",
    "    XY = np.hstack([X_train, y_train])  # shape (n_samples, 6)\n",
    "    \n",
    "    # Fit a Gaussian Mixture Model to the joint distribution\n",
    "    n_components = 6\n",
    "    gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state = 42)\n",
    "    gmm.fit(XY)\n",
    "\n",
    "    gmm_train_pred = gmr_multivariate(gmm, X_train)\n",
    "    gmm_test_pred = gmr_multivariate(gmm, X_test)\n",
    "    \n",
    "    # Combine the original features and the GBR predictions as new inputs for the Neural Network\n",
    "    X_train_nn = np.hstack([X_train, gmm_train_pred.reshape(-1, 1)])\n",
    "    X_test_nn = np.hstack([X_test, gmm_test_pred.reshape(-1, 1)])\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_nn, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "    X_test_tensor = torch.tensor(X_test_nn, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    # 3. Define a simple neural network in PyTorch\n",
    "    class RegressionNN(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(RegressionNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, 64)\n",
    "            self.fc2 = nn.Linear(64, 128)\n",
    "            self.fc3 = nn.Linear(128, 256)\n",
    "            self.fc4 = nn.Linear(256, 128)\n",
    "            self.fc5 = nn.Linear(128, 64)\n",
    "            self.fc6 = nn.Linear(64, 1)\n",
    "       \n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = torch.relu(self.fc3(x))\n",
    "            x = torch.relu(self.fc4(x))\n",
    "            x = torch.relu(self.fc5(x))\n",
    "            x = self.fc6(x)\n",
    "            return x\n",
    "    \n",
    "    # Create the neural network\n",
    "    input_size = X_train_nn.shape[1]\n",
    "    model = RegressionNN(input_size)\n",
    "    \n",
    "    # 4. Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Regularization parameters\n",
    "    lambda_l1 = 0   # L1 penalty strength\n",
    "    lambda_l2 = 1e-4   # L2 penalty strength\n",
    "\n",
    "    # L2 can also be directly included in the optimizer as weight_decay\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=lambda_l2)\n",
    "    \n",
    "    plt.ion()\n",
    "    \n",
    "    # 5. Train the Neural Network\n",
    "    n_epochs = 1000 # Default 1000\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "       \n",
    "        # Forward pass\n",
    "        y_train_pred = model(X_train_tensor)\n",
    "        y_test_pred  = model(X_test_tensor)\n",
    "        loss = criterion(y_train_pred, y_train_tensor)\n",
    "        \n",
    "        #Note: L2 Regularization already handled in optimizer via weight_decay\n",
    "\n",
    "        # Add L1 Regularization\n",
    "        l1_norm = sum(param.abs().sum() for param in model.parameters())\n",
    "        loss += lambda_l1 * l1_norm\n",
    "       \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Obtaining R2 scores for train and test datasets\n",
    "        var_train = r2_score(y_train_tensor.data.numpy(), y_train_pred.detach().numpy())\n",
    "        var_test  = r2_score(y_test_tensor.data.numpy(), y_test_pred.detach().numpy())\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}')\n",
    "            print(\"Train R^2: \", var_train)\n",
    "            print(\"Test  R^2: \", var_test)\n",
    "\n",
    "            fig, axes = plt.subplots(2, 2, figsize = (7,5))\n",
    "            axes[0, 0].scatter(y_train_tensor, y_train_pred.detach().numpy())\n",
    "            axes[0, 0].plot([min(y_train_tensor.data.numpy()), max(y_train_tensor.data.numpy())],[min(y_train_tensor.data.numpy()), max(y_train_tensor.data.numpy())], color = 'r')\n",
    "            axes[0, 0].set_title(\"Training Data\")\n",
    "            axes[0, 0].set_xlabel(\"Actual values\")\n",
    "            axes[0, 0].set_ylabel(\"Predicted values\")\n",
    "    \n",
    "            axes[0, 1].scatter(y_test_tensor, y_test_pred.detach().numpy())\n",
    "            axes[0, 1].plot([min(y_test_tensor.data.numpy()), max(y_test_tensor.data.numpy())],[min(y_test_tensor.data.numpy()), max(y_test_tensor.data.numpy())], color = 'r')\n",
    "            axes[0, 1].set_title(\"Test Data\")\n",
    "            axes[0, 1].set_xlabel(\"Actual values\")\n",
    "            axes[0, 1].set_ylabel(\"Predicted values\")\n",
    "    \n",
    "            axes[1, 0].plot(y_train_tensor.data.numpy().squeeze()*10,'tab:orange', label = 'real')\n",
    "            axes[1, 0].plot(y_train_pred.detach().numpy()*10,'tab:green',label = 'pred')\n",
    "            axes[1, 0].set_xlabel(\"Sample Number\")\n",
    "            axes[1, 0].set_ylabel(\"Fatigue Constant Value\")\n",
    "            axes[1, 0].legend()\n",
    "    \n",
    "            axes[1, 1].plot(y_test_tensor.data.numpy().squeeze()*10, 'tab:orange',label = 'real')\n",
    "            axes[1, 1].plot(y_test_pred.detach().numpy()*10,'tab:green',label = 'pred')\n",
    "            axes[1, 1].set_xlabel(\"Sample Number\")\n",
    "            axes[1, 1].set_ylabel(\"Fatigue Constant Value\")\n",
    "            axes[1, 1].legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # # Scatter plot - Train\n",
    "            # min_train, max_train = y_train_tensor.min().item(), y_train_tensor.max().item()\n",
    "            # axes[0, 0].scatter(y_train_tensor, y_train_pred.detach().numpy())\n",
    "            # axes[0, 0].plot([min_train, max_train], [min_train, max_train], 'r')\n",
    "            # axes[0, 0].set_title(\"Training Data\")\n",
    "            # axes[0, 0].set_xlabel(\"Actual values\")\n",
    "            # axes[0, 0].set_ylabel(\"Predicted values\")\n",
    "            \n",
    "            # # Scatter plot - Test\n",
    "            # min_test, max_test = y_test_tensor.min().item(), y_test_tensor.max().item()\n",
    "            # axes[0, 1].scatter(y_test_tensor, y_test_pred.detach().numpy())\n",
    "            # axes[0, 1].plot([min_test, max_test], [min_test, max_test], 'r')\n",
    "            # axes[0, 1].set_title(\"Test Data\")\n",
    "            # axes[0, 1].set_xlabel(\"Actual values\")\n",
    "            # axes[0, 1].set_ylabel(\"Predicted values\")\n",
    "            \n",
    "            # # Line plot - Train\n",
    "            # axes[1, 0].plot(y_train_tensor.numpy().squeeze() * 10, 'tab:orange', label='real')\n",
    "            # axes[1, 0].plot(y_train_pred.detach().numpy() * 10, 'tab:green', label='pred')\n",
    "            # axes[1, 0].set_xlabel(\"Sample Number\")\n",
    "            # axes[1, 0].set_ylabel(\"Fatigue Constant Value\")\n",
    "            # axes[1, 0].legend()\n",
    "            \n",
    "            # # Line plot - Test\n",
    "            # axes[1, 1].plot(y_test_tensor.numpy().squeeze() * 10, 'tab:orange', label='real')\n",
    "            # axes[1, 1].plot(y_test_pred.detach().numpy() * 10, 'tab:green', label='pred')\n",
    "            # axes[1, 1].set_xlabel(\"Sample Number\")\n",
    "            # axes[1, 1].set_ylabel(\"Fatigue Constant Value\")\n",
    "            # axes[1, 1].legend()\n",
    "            # plt.tight_layout()\n",
    "            \n",
    "            plt.show()\n",
    "    \n",
    "            plt.draw();plt.pause(0.05)\n",
    "    \n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Evaluate the model on the test data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_predictions = model(X_test_tensor)\n",
    "        test_loss = mean_squared_error(y_test_tensor.numpy(), test_predictions.numpy())\n",
    "        print(f'Test MSE: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cde0911-1a57-4808-9cc3-5bfc8353f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason Ng\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.7789667788358388\n",
      "Test  R^2:  0.5933736676584871\n",
      "tensor([[-7.8849e-01],\n",
      "        [ 4.4615e-01],\n",
      "        [-2.6405e+00],\n",
      "        [-5.0789e-01],\n",
      "        [-1.7117e-01],\n",
      "        [-2.2729e-01],\n",
      "        [-1.1505e-01],\n",
      "        [ 7.2676e-01],\n",
      "        [-3.9565e-01],\n",
      "        [ 1.7369e+00],\n",
      "        [ 6.7064e-01],\n",
      "        [-1.0691e+00],\n",
      "        [-7.8849e-01],\n",
      "        [-1.7986e+00],\n",
      "        [-2.9211e+00],\n",
      "        [ 1.0074e+00],\n",
      "        [-1.1505e-01],\n",
      "        [ 7.8288e-01],\n",
      "        [ 4.4615e-01],\n",
      "        [ 1.0074e+00],\n",
      "        [ 4.4615e-01],\n",
      "        [-5.6401e-01],\n",
      "        [-1.7986e+00],\n",
      "        [-5.0789e-01],\n",
      "        [-5.8926e-02],\n",
      "        [ 7.2676e-01],\n",
      "        [ 1.0074e+00],\n",
      "        [ 1.1757e+00],\n",
      "        [-1.7117e-01],\n",
      "        [ 3.3391e-01],\n",
      "        [-4.5177e-01],\n",
      "        [ 3.3391e-01],\n",
      "        [ 3.9003e-01],\n",
      "        [-1.1505e-01],\n",
      "        [-1.0691e+00],\n",
      "        [-2.8060e-03],\n",
      "        [ 2.7779e-01],\n",
      "        [-4.5177e-01],\n",
      "        [ 4.4615e-01],\n",
      "        [ 9.5124e-01],\n",
      "        [-1.7986e+00],\n",
      "        [-1.1505e-01],\n",
      "        [-1.1813e+00],\n",
      "        [ 8.3900e-01],\n",
      "        [ 5.0227e-01],\n",
      "        [ 1.2318e+00],\n",
      "        [-6.7625e-01],\n",
      "        [-2.1354e+00]])\n",
      "tensor([[0.0609],\n",
      "        [0.0719],\n",
      "        [0.0708],\n",
      "        [0.0729],\n",
      "        [0.0681],\n",
      "        [0.0698],\n",
      "        [0.0530],\n",
      "        [0.0685],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0743],\n",
      "        [0.0676],\n",
      "        [0.0714],\n",
      "        [0.0614],\n",
      "        [0.0712],\n",
      "        [0.0732],\n",
      "        [0.0664],\n",
      "        [0.0719],\n",
      "        [0.0677],\n",
      "        [0.0638],\n",
      "        [0.0693],\n",
      "        [0.0715],\n",
      "        [0.0644],\n",
      "        [0.0723],\n",
      "        [0.0562],\n",
      "        [0.0691],\n",
      "        [0.0719],\n",
      "        [0.0666],\n",
      "        [0.0620],\n",
      "        [0.0581],\n",
      "        [0.0721],\n",
      "        [0.0708],\n",
      "        [0.0659],\n",
      "        [0.0705],\n",
      "        [0.0712],\n",
      "        [0.0699],\n",
      "        [0.0714],\n",
      "        [0.0690],\n",
      "        [0.0695],\n",
      "        [0.0610],\n",
      "        [0.0678],\n",
      "        [0.0678],\n",
      "        [0.0674],\n",
      "        [0.0683],\n",
      "        [0.0741],\n",
      "        [0.0721],\n",
      "        [0.0676],\n",
      "        [0.0697]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 169\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# Obtaining R2 scores for train and test datasets\u001b[39;00m\n\u001b[0;32m    168\u001b[0m var_train \u001b[38;5;241m=\u001b[39m r2_score(y_train_tensor\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy(), y_train_pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m--> 169\u001b[0m var_test  \u001b[38;5;241m=\u001b[39m r2_score(y_test_tensor\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy(), y_test_pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:911\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mr2_score\u001b[39m(\n\u001b[0;32m    785\u001b[0m     y_true,\n\u001b[0;32m    786\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m     force_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    791\u001b[0m ):\n\u001b[0;32m    792\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \n\u001b[0;32m    794\u001b[0m \u001b[38;5;124;03m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m    -inf\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 911\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    912\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 101\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m     )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    921\u001b[0m     _assert_all_finite(\n\u001b[0;32m    922\u001b[0m         array,\n\u001b[0;32m    923\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "OMP_NUM_THREADS=1\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "root = \"tensile_fatigue_data_v14.xlsx\"\n",
    "main_df = pd.read_excel(root)\n",
    "\n",
    "X = pd.read_excel(root,usecols=[0,1,2,3,4])\n",
    "y = pd.read_excel(root,usecols=[6])\n",
    "\n",
    "# Normalize inputs\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size= 0.2, random_state = 10)\n",
    "\n",
    "# Stack inputs and output for joint modeling\n",
    "XY = np.hstack([X_train, y_train.reshape(-1, 1)])  # shape (n_samples, 6)\n",
    "\n",
    "# Fit a Gaussian Mixture Model to the joint distribution\n",
    "n_components = 6\n",
    "gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=42)\n",
    "gmm.fit(XY)\n",
    "\n",
    "def gmr_multivariate(gmm, X_query):\n",
    "    \"\"\"\n",
    "    Perform Gaussian Mixture Regression with multivariate X and scalar Y.\n",
    "    :param gmm: Trained GaussianMixture model (on joint [X, Y])\n",
    "    :param X_query: Input queries of shape (n_queries, n_features)\n",
    "    :return: Predicted Y values (mean), shape (n_queries,)\n",
    "    \"\"\"\n",
    "    n_queries = X_query.shape[0]\n",
    "    n_features = X_query.shape[1]\n",
    "    y_preds = np.zeros(n_queries)\n",
    "\n",
    "    for i in range(n_queries):\n",
    "        x = X_query[i].reshape(-1, 1)  # shape (n_features, 1)\n",
    "\n",
    "        weights = []\n",
    "        means = []\n",
    "\n",
    "        for k in range(gmm.n_components):\n",
    "            mu = gmm.means_[k].reshape(-1, 1)          # shape (6, 1)\n",
    "            Sigma = gmm.covariances_[k]                # shape (6, 6)\n",
    "\n",
    "            mu_x = mu[:n_features]\n",
    "            mu_y = mu[n_features:]\n",
    "            Sigma_xx = Sigma[:n_features, :n_features]\n",
    "            Sigma_xy = Sigma[:n_features, n_features:]\n",
    "            Sigma_yx = Sigma[n_features:, :n_features]\n",
    "            Sigma_yy = Sigma[n_features:, n_features:]\n",
    "\n",
    "            # Compute conditional mean E[Y | X=x]\n",
    "            inv_Sigma_xx = np.linalg.inv(Sigma_xx)\n",
    "            cond_mean = mu_y + Sigma_yx @ inv_Sigma_xx @ (x - mu_x)  # shape (1, 1)\n",
    "            means.append(cond_mean.flatten())\n",
    "\n",
    "            # Compute responsibility (weight) for component k\n",
    "            diff = x.flatten() - mu_x.flatten()\n",
    "            exponent = -0.5 * diff @ inv_Sigma_xx @ diff\n",
    "            norm_const = np.sqrt((2 * np.pi) ** n_features * np.linalg.det(Sigma_xx))\n",
    "            prob = np.exp(exponent) / norm_const\n",
    "            weights.append(gmm.weights_[k] * prob)\n",
    "\n",
    "        weights = np.array(weights)\n",
    "        weights /= np.sum(weights)\n",
    "        means = np.array(means).flatten()\n",
    "        y_preds[i] = np.sum(weights * means)\n",
    "\n",
    "    return y_preds\n",
    "\n",
    "# Query on test inputs\n",
    "gmm_train_pred = gmr_multivariate(gmm, X_train)\n",
    "gmm_test_pred = gmr_multivariate(gmm, X_test)\n",
    "\n",
    "var_train = r2_score(y_train, gmm_train_pred)\n",
    "var_test  = r2_score(y_test, gmm_test_pred)\n",
    "\n",
    "print(\"Train R^2: \", var_train)\n",
    "print(\"Test  R^2: \", var_test)\n",
    "\n",
    "gmm_train_pred = gmr_multivariate(gmm, X_train)\n",
    "gmm_test_pred = gmr_multivariate(gmm, X_test)\n",
    "\n",
    "# Combine the original features and the GBR predictions as new inputs for the Neural Network\n",
    "X_train_nn = np.hstack([X_train, gmm_train_pred.reshape(-1, 1)])\n",
    "X_test_nn = np.hstack([X_test, gmm_test_pred.reshape(-1, 1)])\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_nn, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).reshape(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_nn, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# 3. Define a simple neural network in PyTorch\n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 1)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "# Create the neural network\n",
    "input_size = X_train_nn.shape[1]\n",
    "model = RegressionNN(input_size)\n",
    "\n",
    "# 4. Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Regularization parameters\n",
    "lambda_l1 = 0   # L1 penalty strength\n",
    "lambda_l2 = 1e-4   # L2 penalty strength\n",
    "\n",
    "# L2 can also be directly included in the optimizer as weight_decay\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=lambda_l2)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# 5. Train the Neural Network\n",
    "n_epochs = 1000 # Default 1000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "   \n",
    "    # Forward pass\n",
    "    y_train_pred = model(X_train_tensor)\n",
    "    y_test_pred  = model(X_test_tensor)\n",
    "    loss = criterion(y_train_pred, y_train_tensor)\n",
    "    \n",
    "    #Note: L2 Regularization already handled in optimizer via weight_decay\n",
    "\n",
    "    # Add L1 Regularization\n",
    "    l1_norm = sum(param.abs().sum() for param in model.parameters())\n",
    "    loss += lambda_l1 * l1_norm\n",
    "   \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(y_train_tensor)\n",
    "    print(y_train_pred)\n",
    "    \n",
    "    # Obtaining R2 scores for train and test datasets\n",
    "    var_train = r2_score(y_train_tensor.data.numpy(), y_train_pred.detach().numpy())\n",
    "    var_test  = r2_score(y_test_tensor.data.numpy(), y_test_pred.detach().numpy())\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}')\n",
    "        print(\"Train R^2: \", var_train)\n",
    "        print(\"Test  R^2: \", var_test)\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize = (7,5))\n",
    "        axes[0, 0].scatter(y_train_tensor, y_train_pred.detach().numpy())\n",
    "        axes[0, 0].plot([min(y_train_tensor.data.numpy()), max(y_train_tensor.data.numpy())],[min(y_train_tensor.data.numpy()), max(y_train_tensor.data.numpy())], color = 'r')\n",
    "        axes[0, 0].set_title(\"Training Data\")\n",
    "        axes[0, 0].set_xlabel(\"Actual values\")\n",
    "        axes[0, 0].set_ylabel(\"Predicted values\")\n",
    "\n",
    "        axes[0, 1].scatter(y_test_tensor, y_test_pred.detach().numpy())\n",
    "        axes[0, 1].plot([min(y_test_tensor.data.numpy()), max(y_test_tensor.data.numpy())],[min(y_test_tensor.data.numpy()), max(y_test_tensor.data.numpy())], color = 'r')\n",
    "        axes[0, 1].set_title(\"Test Data\")\n",
    "        axes[0, 1].set_xlabel(\"Actual values\")\n",
    "        axes[0, 1].set_ylabel(\"Predicted values\")\n",
    "\n",
    "        axes[1, 0].plot(y_train_tensor.data.numpy().squeeze()*10,'tab:orange', label = 'real')\n",
    "        axes[1, 0].plot(y_train_pred.detach().numpy()*10,'tab:green',label = 'pred')\n",
    "        axes[1, 0].set_xlabel(\"Sample Number\")\n",
    "        axes[1, 0].set_ylabel(\"Fatigue Constant Value\")\n",
    "        axes[1, 0].legend()\n",
    "\n",
    "        axes[1, 1].plot(y_test_tensor.data.numpy().squeeze()*10, 'tab:orange',label = 'real')\n",
    "        axes[1, 1].plot(y_test_pred.detach().numpy()*10,'tab:green',label = 'pred')\n",
    "        axes[1, 1].set_xlabel(\"Sample Number\")\n",
    "        axes[1, 1].set_ylabel(\"Fatigue Constant Value\")\n",
    "        axes[1, 1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        plt.draw();plt.pause(0.05)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38e473a0-4da9-48e3-ad26-3dad3cbd83a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m Y \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(root,usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m6\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Combine for GMM fitting\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m XY \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([X, Y\u001b[38;5;241m.\u001b[39mravel()])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ---- GMM Regression Setup ----\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgmr_predict\u001b[39m(gmm, X_query):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ravel'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Generate data ----\n",
    "root = \"tensile_fatigue_data_v14.xlsx\"\n",
    "main_df = pd.read_excel(root)\n",
    "\n",
    "X = pd.read_excel(root,usecols=[0,1,2,3,4])\n",
    "Y = pd.read_excel(root,usecols=[6])\n",
    "\n",
    "# Combine for GMM fitting\n",
    "XY = np.hstack([X, Y.ravel()])\n",
    "\n",
    "# ---- GMM Regression Setup ----\n",
    "def gmr_predict(gmm, X_query):\n",
    "    n_queries = X_query.shape[0]\n",
    "    n_features = X_query.shape[1]\n",
    "    y_preds = np.zeros(n_queries)\n",
    "\n",
    "    for i in range(n_queries):\n",
    "        x = X_query[i].reshape(-1, 1)\n",
    "        weights = []\n",
    "        means = []\n",
    "\n",
    "        for k in range(gmm.n_components):\n",
    "            mu = gmm.means_[k].reshape(-1, 1)\n",
    "            Sigma = gmm.covariances_[k]\n",
    "\n",
    "            mu_x = mu[:n_features]\n",
    "            mu_y = mu[n_features:]\n",
    "            Sigma_xx = Sigma[:n_features, :n_features]\n",
    "            Sigma_yx = Sigma[n_features:, :n_features]\n",
    "\n",
    "            inv_Sigma_xx = np.linalg.inv(Sigma_xx)\n",
    "            cond_mean = mu_y + Sigma_yx @ inv_Sigma_xx @ (x - mu_x)\n",
    "            means.append(cond_mean.flatten())\n",
    "\n",
    "            diff = x.flatten() - mu_x.flatten()\n",
    "            exponent = -0.5 * diff @ inv_Sigma_xx @ diff\n",
    "            norm_const = np.sqrt((2 * np.pi) ** n_features * np.linalg.det(Sigma_xx))\n",
    "            prob = np.exp(exponent) / norm_const\n",
    "            weights.append(gmm.weights_[k] * prob)\n",
    "\n",
    "        weights = np.array(weights)\n",
    "        weights /= np.sum(weights)\n",
    "        means = np.array(means).flatten()\n",
    "        y_preds[i] = np.sum(weights * means)\n",
    "\n",
    "    return y_preds\n",
    "\n",
    "# Fit GMM on [X, Y]\n",
    "gmm = GaussianMixture(n_components=6, covariance_type='full', random_state=42)\n",
    "gmm.fit(XY)\n",
    "\n",
    "# ---- Get GMM predictions and augment features ----\n",
    "y_gmm = gmr_predict(gmm, X).reshape(-1, 1)\n",
    "X_aug = np.hstack([X, y_gmm])  # 5 original + 1 GMM feature\n",
    "\n",
    "# ---- Train-test split ----\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_aug, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---- DNN Model ----\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(6, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "# ---- Training ----\n",
    "model = DNNModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 300\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ---- Evaluation ----\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test_tensor).numpy().flatten()\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "print(f\"\\nTest RMSE: {rmse:.4f}\")\n",
    "\n",
    "# ---- Plot predictions ----\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"True Y\")\n",
    "plt.ylabel(\"Predicted Y (Hybrid GMM+DNN)\")\n",
    "plt.title(\"Prediction vs Ground Truth\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5b7c8-f8f7-46a7-a628-5371fb4f960d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
